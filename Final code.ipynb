{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the library\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comment this if the data visualisations doesn't work on your side\n",
    "print(\"TensorFlow v\" + tf.__version__)\n",
    "print(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n",
    "\n",
    "#Load the dataset\n",
    "train_file_path = \"D:/QTDL with Spark/train.csv\"\n",
    "dataset_df = pd.read_csv(train_file_path)\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n",
    "dataset_df.head(3)\n",
    "#There are 79 feature columns. Using these features your model has to predict the house sale price indicated by the label column named SalePrice.\n",
    "dataset_df = dataset_df.drop('Id', axis=1)\n",
    "dataset_df.head(3)\n",
    "dataset_df.info()\n",
    "train_file_path.describe()\n",
    "train_file_path.isnull().sum()\n",
    "train_file_path = df.dropna(axis=1)\n",
    "print(train_file_path) \n",
    "\n",
    "#House Price Distribution\n",
    "print(dataset_df['SalePrice'].describe())\n",
    "plt.figure(figsize=(9, 8))\n",
    "sns.histplot(dataset_df['SalePrice'], color='g', bins=100, hist_kws={'alpha': 0.4})\n",
    "\n",
    "#Numerical data distribution\n",
    "list(set(dataset_df.dtypes.tolist()))\n",
    "df_num = dataset_df.select_dtypes(include = ['float64', 'int64'])\n",
    "df_num.head()\n",
    "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)\n",
    "\n",
    "#Prepare the dataset\n",
    "\n",
    "\n",
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "train_ds_pd, valid_ds_pd = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(valid_ds_pd)))\n",
    "label = 'SalePrice'\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\n",
    "valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\n",
    "#Select a Model\n",
    "tfdf.keras.get_all_models()\n",
    "rf = tfdf.keras.RandomForestModel(hyperparameter_template=\"benchmark_rank1\", task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "#Create a Random Forest\n",
    "rf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
    "rf.compile(metrics=[\"mse\"]) # Optional, you can use this to include a list of eval metrics\n",
    "\n",
    "#Train the model\n",
    "rf.fit(x=train_ds)\n",
    "\n",
    "#Visualize the model\n",
    "tfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=3)\n",
    "\n",
    "#Evaluate the model on the Out of bag (OOB) data and the validation dataset\n",
    "\n",
    "logs = rf.make_inspector().training_logs()\n",
    "plt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"RMSE (out-of-bag)\")\n",
    "plt.show()\n",
    "inspector = rf.make_inspector()\n",
    "inspector.evaluation()\n",
    "evaluation = rf.evaluate(x=valid_ds,return_dict=True)\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "#Variable importances\n",
    "print(f\"Available variable importances:\")\n",
    "for importance in inspector.variable_importances().keys():\n",
    "  print(\"\\t\", importance)\n",
    "\n",
    "inspector.variable_importances()[\"NUM_AS_ROOT\"]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Mean decrease in AUC of the class 1 vs the others.\n",
    "variable_importance_metric = \"NUM_AS_ROOT\"\n",
    "variable_importances = inspector.variable_importances()[variable_importance_metric]\n",
    "\n",
    "# Extract the feature name and importance values.\n",
    "#\n",
    "# `variable_importances` is a list of <feature, importance> tuples.\n",
    "feature_names = [vi[0].name for vi in variable_importances]\n",
    "feature_importances = [vi[1] for vi in variable_importances]\n",
    "# The feature are ordered in decreasing importance value.\n",
    "feature_ranks = range(len(feature_names))\n",
    "\n",
    "bar = plt.barh(feature_ranks, feature_importances, label=[str(x) for x in feature_ranks])\n",
    "plt.yticks(feature_ranks, feature_names)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# TODO: Replace with \"plt.bar_label()\" when available.\n",
    "# Label each bar with values\n",
    "for importance, patch in zip(feature_importances, bar.patches):\n",
    "  plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{importance:.4f}\", va=\"top\")\n",
    "\n",
    "plt.xlabel(variable_importance_metric)\n",
    "plt.title(\"NUM AS ROOT of the class 1 vs the others\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Submission\n",
    "test_file_path = \"D:/QTDL with Spark/test.csv\"\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "ids = test_data.pop('Id')\n",
    "\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n",
    "    test_data,\n",
    "    task = tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "preds = rf.predict(test_ds)\n",
    "output = pd.DataFrame({'Id': ids,\n",
    "                       'SalePrice': preds.squeeze()})\n",
    "\n",
    "output.head()\n",
    "\n",
    "ample_submission_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
    "sample_submission_df['SalePrice'] = rf.predict(test_ds)\n",
    "sample_submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "sample_submission_df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
